{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze A/B Test Results\n",
    "\n",
    "## Table of Contents\n",
    "- [Introduction](#intro)\n",
    "- [Part I - Probability](#probability)\n",
    "- [Part II - A/B Test](#ab_test)\n",
    "- [Part III - Regression](#regression)\n",
    "\n",
    "\n",
    "<a id='intro'></a>\n",
    "### Introduction\n",
    "\n",
    "For this project, I will be working to understand the results of an A/B test run by an e-commerce website.  My goal is to work through this notebook to help the company understand if they should implement the new page, keep the old page, or perhaps run the experiment longer to make their decision.\n",
    "\n",
    "<a id='probability'></a>\n",
    "#### Part I - Probability\n",
    "\n",
    "To get started, let's import our libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "#We are setting the seed to assure you get the same answers on quizzes as we set up\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>851104</td>\n",
       "      <td>2017-01-21 22:11:48.556739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>804228</td>\n",
       "      <td>2017-01-12 08:01:45.159739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>661590</td>\n",
       "      <td>2017-01-11 16:55:06.154213</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>853541</td>\n",
       "      <td>2017-01-08 18:28:03.143765</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>864975</td>\n",
       "      <td>2017-01-21 01:52:26.210827</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                   timestamp      group landing_page  converted\n",
       "0   851104  2017-01-21 22:11:48.556739    control     old_page          0\n",
       "1   804228  2017-01-12 08:01:45.159739    control     old_page          0\n",
       "2   661590  2017-01-11 16:55:06.154213  treatment     new_page          0\n",
       "3   853541  2017-01-08 18:28:03.143765  treatment     new_page          0\n",
       "4   864975  2017-01-21 01:52:26.210827    control     old_page          1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read in ab_data.csv and store in df, taking a look at the first few rows\n",
    "df = pd.read_csv('ab_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(294478, 5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find number of rows in dataset\n",
    "df.shape\n",
    "#294478 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "290584"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The number of unique users in the dataset\n",
    "df.user_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11965919355605512"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#proportion of users converted\n",
    "df.converted.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The number of times the `new_page` and `treatment` don't line up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3893"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#number of times treatment group member does not receive the new page\n",
    "df[((df['group'] == 'treatment') == (df['landing_page'] == 'new_page')) == False].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do any of the rows have missing values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id         0\n",
       "timestamp       0\n",
       "group           0\n",
       "landing_page    0\n",
       "converted       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#no nulls/missing values in any rows\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`2.` For the rows where **treatment** is not aligned with **new_page** or **control** is not aligned with **old_page**, we cannot be sure if this row truly received the new or old page. We need to drop the rows where a treatment group member does not receive the new page and assign new dataframe for df2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop all rows where treatment and new_page don't line up and assign that new dataframe to df2\n",
    "df2 = df.drop(df[((df['group'] == 'treatment') == (df['landing_page'] == 'new_page')) == False].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Double Check all of the correct rows were removed - this should be 0\n",
    "df2[((df2['group'] == 'treatment') == (df2['landing_page'] == 'new_page')) == False].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "290584"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#unique user ids in df2\n",
    "df2.user_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "773192"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#User Id that appears twice in df2\n",
    "nonunique = df2.user_id.value_counts()\n",
    "nonunique[nonunique > 1].index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1899</th>\n",
       "      <td>773192</td>\n",
       "      <td>2017-01-09 05:37:58.781806</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2893</th>\n",
       "      <td>773192</td>\n",
       "      <td>2017-01-14 02:55:59.590927</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id                   timestamp      group landing_page  converted\n",
       "1899   773192  2017-01-09 05:37:58.781806  treatment     new_page          0\n",
       "2893   773192  2017-01-14 02:55:59.590927  treatment     new_page          0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#row info for the repeat user id\n",
    "df2.query('user_id == 773192')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop one of the duplicate user id rows\n",
    "df2 = df2.drop(df2.index[2893])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11959708724499628"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#probability of an individual converting regardless of page they receive\n",
    "df2.converted.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1203863045004612"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#probability of individual converting given they are in the control group\n",
    "c_ctrl = df2.query('group == \"control\"')['converted'].mean()\n",
    "c_ctrl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11880806551510564"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#probability of an individual converting given that they are in the treatment group\n",
    "c_trt = df2.query('group == \"treatment\"')['converted'].mean()\n",
    "c_trt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0015782389853555567"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#observed difference in conversion rates between control and treatment group\n",
    "obs_diff = c_trt-c_ctrl\n",
    "obs_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5000619442226688"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#probability that an individual received the new page\n",
    "df2.query('landing_page == \"new_page\"').shape[0]/df2['landing_page'].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**No evidence so far that one page leads to more conversions.**\n",
    "> Across the board, conversion rate is 12%, whether we're looking at aggregate conversion rates, only amongst those in treatment or control group. There is no evidence thus far that one page leads to more conversions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ab_test'></a>\n",
    "### Part II - A/B Test\n",
    "\n",
    "Because of the time stamp associated with each event, we could technically run a hypothesis test continuously as each observation was observed.  \n",
    "\n",
    "However, then the hard question is do we stop as soon as one page is considered significantly better than another or does it need to happen consistently for a certain amount of time?  How long do we run to render a decision that neither page is better than another?  \n",
    "\n",
    "These questions are the difficult parts associated with A/B tests in general.  \n",
    "\n",
    "\n",
    "`1.` For now, we're going to try and make a decision just based on all the data provided.  We want to assume that the old page is better unless the new page proves to be definitely better at a Type I error rate of 5%.  **$p_{old}$** and **$p_{new}$** are the converted rates for the old and new pages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **$H_{O}$**: **$p_{new}$** - **$p_{old}$** <= 0\n",
    "\n",
    "> **$H_{A}$**: **$p_{new}$** - **$p_{old}$** > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`2.` We'll assume under the null hypothesis, $p_{new}$ and $p_{old}$ both have \"true\" success rates equal to the **converted** success rate regardless of page - that is $p_{new}$ and $p_{old}$ are equal. Furthermore, assume they are equal to the **converted** rate in **ab_data.csv** regardless of the page. <br><br>\n",
    "\n",
    "We'll use a sample size for each page equal to the ones in **ab_data.csv**.  <br><br>\n",
    "\n",
    "We'll perform the sampling distribution for the difference in **converted** between the two pages over 10,000 iterations of calculating an estimate from the null.  <br><br>\n",
    "\n",
    "Use the following cells below to complete the necessary parts of this simulation. <br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a.  **convert rate** for $p_{new}$ under the null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11959708724499628"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert rate for p_new is the same as convert rate for dataset regardless of ab group\n",
    "p_new = df2.converted.mean()\n",
    "p_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. **convert rate** for $p_{old}$ under the null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11959708724499628"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert rate for p_old is the same as convert rate for dataset regardless of ab group\n",
    "p_old = df2.converted.mean()\n",
    "p_old"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. $n_{new}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145310"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sample size for the new page aka the treatment group, is the same as the size of the treatment group\n",
    "n_new = df2.query('group == \"treatment\"').shape[0]\n",
    "n_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d. $n_{old}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145274"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sample size for the old page aka the control group, is the same as the size of the control group\n",
    "n_old = df2.query('group == \"control\"').shape[0]\n",
    "n_old"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e. Simulate $n_{new}$ transactions with a convert rate of $p_{new}$ under the null.  Store these $n_{new}$ 1's and 0's in **new_page_converted**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_page_converted = np.random.binomial(1, p_new, n_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f. Simulate $n_{old}$ transactions with a convert rate of $p_{old}$ under the null.  Store these $n_{old}$ 1's and 0's in **old_page_converted**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_page_converted = np.random.binomial(1, p_old, n_old)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "g. Find $p_{new}$ - $p_{old}$ for your simulated values from part (e) and (f)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00010799059139121603"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# difference in average conversions for above simulations between control and treatment group\n",
    "(new_page_converted.mean()) - (old_page_converted.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "h. Simulate 10,000 $p_{new}$ - $p_{old}$ values using this same process.  Store all 10,000 values in **p_diffs**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#simulate 10,000 new page conversions of trial size n_new\n",
    "new_page_conversions = np.random.binomial(n_new,p_new,10000)\n",
    "\n",
    "#simulate 10,000 old page conversions of trial size n_old\n",
    "old_page_conversions = np.random.binomial(n_old,p_old,10000)\n",
    "\n",
    "#calculate the difference in proportion of conversions between all the simulations above\n",
    "p_diffs = [(x/n_new) - (y/n_old) for x, y in zip(new_page_conversions, old_page_conversions)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i. Plot a histogram of the **p_diffs** and a red line marking where obs_diff is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x108b64898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(p_diffs)\n",
    "plt.axvline(obs_diff, c='r');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "j. Proportion of **p_diffs** greater than the actual difference observed in **ab_data.csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9005"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''add up the number of times a value in p_diffs was greater than obs_diff from Part 1\n",
    "    and divide that by total number of values in p_diffs'''\n",
    "p_obs_diff = 0\n",
    "for i in p_diffs:\n",
    "    if i > obs_diff:\n",
    "        p_obs_diff += 1\n",
    "        \n",
    "(p_obs_diff/len(p_diffs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Results.**\n",
    "\n",
    "> Here we calculated differences between new page conversion rates and old page conversion rates in our simulations, and then found how the proportion of those differences that are greater than the difference we calculated in our actual data. Based upon how we set up our hypothesis test, this calculation turned out to be a p-value in scientific studies, and it determines whether or not the difference between new and old pages is statistically significant. This is the probability of seeing a difference in conversions as extreme or more extreme than our actual observations, under our null hypothesis.\n",
    "\n",
    "> With our p-value over .05, we do no have statistically significant evidence to reject the null that conversion rate differences between the old page and new page are less than or equal to 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "l. We could also use a built-in to achieve similar results.  Though using the built-in might be easier to code, the above portions are a walkthrough of the ideas that are critical to correctly thinking about statistical significance. Fill in the below to calculate the number of conversions for each page, as well as the number of individuals who received each page. Let `n_old` and `n_new` refer the the number of rows associated with the old page and new pages, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/christinacaddel/anaconda3/envs/sampling_distrib/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "convert_old = df2.query('group == \"control\" and converted == 1').shape[0]\n",
    "convert_new = df2.query('group == \"treatment\" and converted == 1').shape[0]\n",
    "n_old = df2.query('group == \"control\"').shape[0]\n",
    "n_new = df2.query('group == \"treatment\"').shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "m. Now we use `stats.proportions_ztest` to compute your test statistic and p-value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.3109241984234394, 0.18988337448195103)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#compute test statistic and p-value for two-sided hypothesis test in which\n",
    "#conversion rate difference is not equal to observed difference\n",
    "z_score, p_value = sm.stats.proportions_ztest([convert_old, convert_new], [n_old, n_new])\n",
    "z_score, p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.3109241984234394, 0.094941687240975514)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#compute test statistic and p-value for one-sided hypothesis test in which\n",
    "#conversion rate difference is greater than observed difference\n",
    "z_score, p_value = sm.stats.proportions_ztest([convert_old, convert_new], [n_old, n_new], alternative = 'larger')\n",
    "z_score, p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Statistical Significance**\n",
    "\n",
    "> According to the z-scores and p-values computed above, we do no have statistically significant evidence to reject the null for either hypothesis test. One difference here, is that in parts j. and k. we are calculating the p-value for a one-sided hypothesis where we are only looking for p_new - p_old > 0. Here we conducted a two-sided hypothesis test where the null hypothesis is that p_new - p_old = 0 and the alternative is that p_new - p_old is not equal to 0. We did also run a one-sided hypothesis test under the same null and alternative as part j. and k. and we did find the same results, a non-statistically significant p-value of .095.\n",
    "\n",
    "> With that, as well as looking over the context of the test, I can also say that there is not practical significance to these results. Thus far, I hold to my argument that implementing the new web page would not result in a consistent improvement in conversion rates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='regression'></a>\n",
    "### Part III - A regression approach\n",
    "\n",
    "`1.` In this final part, we'll achieve the results from the previous A/B test by performing regression.<br><br>\n",
    "\n",
    "a. Since each row is either a conversion or no conversion, we will be performing logistic regression in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. The goal is to use **statsmodels** to fit the regression model we specified in part **a.** to see if there is a significant difference in conversion based on which page a customer receives.  However, we first need to create a column for the intercept, and create a dummy variable column for which page each user received.  Let's add an **intercept** column, as well as an **ab_page** column, which is 1 when an individual receives the **treatment** and 0 if **control**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "      <th>intercept</th>\n",
       "      <th>ab_page</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>851104</td>\n",
       "      <td>2017-01-21 22:11:48.556739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>804228</td>\n",
       "      <td>2017-01-12 08:01:45.159739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>661590</td>\n",
       "      <td>2017-01-11 16:55:06.154213</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>853541</td>\n",
       "      <td>2017-01-08 18:28:03.143765</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>864975</td>\n",
       "      <td>2017-01-21 01:52:26.210827</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                   timestamp      group landing_page  converted  \\\n",
       "0   851104  2017-01-21 22:11:48.556739    control     old_page          0   \n",
       "1   804228  2017-01-12 08:01:45.159739    control     old_page          0   \n",
       "2   661590  2017-01-11 16:55:06.154213  treatment     new_page          0   \n",
       "3   853541  2017-01-08 18:28:03.143765  treatment     new_page          0   \n",
       "4   864975  2017-01-21 01:52:26.210827    control     old_page          1   \n",
       "\n",
       "   intercept  ab_page  \n",
       "0          1        0  \n",
       "1          1        0  \n",
       "2          1        1  \n",
       "3          1        1  \n",
       "4          1        0  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create intercept column and dummy column for ab_page\n",
    "df2['intercept'] = 1\n",
    "df2['ab_page'] = pd.get_dummies(df2['landing_page'])['new_page']\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. Use **statsmodels** to import your regression model.  Instantiate the model, and fit the model using the two columns you created in part **b.** to predict whether or not an individual converts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "stats.chisqprob = lambda chisq, df: stats.chi2.sf(chisq, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.366118\n",
      "         Iterations 6\n"
     ]
    }
   ],
   "source": [
    "logit_mod = sm.Logit(df2['converted'],df2[['intercept','ab_page']])\n",
    "results = logit_mod.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>     <td>converted</td>    <th>  No. Observations:  </th>   <td>290584</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>   <td>290582</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>   <td>     1</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Tue, 12 Dec 2017</td> <th>  Pseudo R-squ.:     </th>  <td>8.077e-06</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>19:42:26</td>     <th>  Log-Likelihood:    </th> <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th> <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th>   <td>0.1899</td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th> <td>   -1.9888</td> <td>    0.008</td> <td> -246.669</td> <td> 0.000</td> <td>   -2.005</td> <td>   -1.973</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ab_page</th>   <td>   -0.0150</td> <td>    0.011</td> <td>   -1.311</td> <td> 0.190</td> <td>   -0.037</td> <td>    0.007</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:              converted   No. Observations:               290584\n",
       "Model:                          Logit   Df Residuals:                   290582\n",
       "Method:                           MLE   Df Model:                            1\n",
       "Date:                Tue, 12 Dec 2017   Pseudo R-squ.:               8.077e-06\n",
       "Time:                        19:42:26   Log-Likelihood:            -1.0639e+05\n",
       "converged:                       True   LL-Null:                   -1.0639e+05\n",
       "                                        LLR p-value:                    0.1899\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "intercept     -1.9888      0.008   -246.669      0.000      -2.005      -1.973\n",
       "ab_page       -0.0150      0.011     -1.311      0.190      -0.037       0.007\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#summary of model\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e. Our p-value associated with **ab_page** here is .19 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the major factor we are considering in terms of our hypotheses and how they are affecting our p-values:\n",
    "\n",
    "> The two-sided hypothesis test that the regression model above ran, and the first values computed in **Part II m.** is stated as follows, and this is what led to our p-value of .19 in those results:\n",
    "\n",
    "    >**$H_{O}$**: **$p_{new}$** - **$p_{old}$** = 0\n",
    "    \n",
    "    >**$H_{A}$**: **$p_{new}$** - **$p_{old}$** â‰  0\n",
    "\n",
    "> Now, the _one-sided_ hypothesis test that **Part II j.** and the second values computed in **Part II m.** is stated in the very first step of **Part II**. And this is what led to our p-value of .095 in those results. As you can see, the two-sided hypothesis test's p-value is the one-sided hypothesis test's p-value multiplied by two to complement the difference in the hypotheses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Considering other things that might influence conversions**\n",
    "\n",
    "> Considering other factors to add into the regression model can open up possibilities of associations with the outcome. Disadvantages to adding additional terms into the regression model are the possibility of collinearity amongst the variables and potentially drawing a misguided conclusion if you base it just on p-values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "g. Now along with testing if the conversion rate changes for different pages, we'll also add an effect based on which country a user lives.\n",
    "\n",
    "Does it appear that country had an impact on conversion? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>834778</td>\n",
       "      <td>UK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>928468</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>822059</td>\n",
       "      <td>UK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>711597</td>\n",
       "      <td>UK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>710616</td>\n",
       "      <td>UK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id country\n",
       "0   834778      UK\n",
       "1   928468      US\n",
       "2   822059      UK\n",
       "3   711597      UK\n",
       "4   710616      UK"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reading in countries.csv, assigning to countries_df and printing head\n",
    "countries_df = pd.read_csv('countries.csv')\n",
    "countries_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 290584 entries, 0 to 290583\n",
      "Data columns (total 2 columns):\n",
      "user_id    290584 non-null int64\n",
      "country    290584 non-null object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 4.4+ MB\n"
     ]
    }
   ],
   "source": [
    "#checking if there are any nulls in countries_df\n",
    "countries_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(290583, 290584)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking if both data frames have the same amount of unique user ids and rows before joining to avoid nulls\n",
    "df2.user_id.nunique(), countries_df.user_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make sure user ids in each dataframe match up\n",
    "df2['user_id'].index.name == countries_df['user_id'].index.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#join countries_df to df2 on the 'user_id' column\n",
    "df2 = df2.join(countries_df.set_index('user_id'),on='user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "US    203619\n",
       "UK     72466\n",
       "CA     14499\n",
       "Name: country, dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get value count for each country to get idea of size\n",
    "df2.country.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dummy variables for the 'country' column and join to df2\n",
    "countries = pd.get_dummies(df2['country'])\n",
    "df2 = df2.join(countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "      <th>intercept</th>\n",
       "      <th>ab_page</th>\n",
       "      <th>country</th>\n",
       "      <th>CA</th>\n",
       "      <th>UK</th>\n",
       "      <th>US</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>851104</td>\n",
       "      <td>2017-01-21 22:11:48.556739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>804228</td>\n",
       "      <td>2017-01-12 08:01:45.159739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>661590</td>\n",
       "      <td>2017-01-11 16:55:06.154213</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>853541</td>\n",
       "      <td>2017-01-08 18:28:03.143765</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>864975</td>\n",
       "      <td>2017-01-21 01:52:26.210827</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                   timestamp      group landing_page  converted  \\\n",
       "0   851104  2017-01-21 22:11:48.556739    control     old_page          0   \n",
       "1   804228  2017-01-12 08:01:45.159739    control     old_page          0   \n",
       "2   661590  2017-01-11 16:55:06.154213  treatment     new_page          0   \n",
       "3   853541  2017-01-08 18:28:03.143765  treatment     new_page          0   \n",
       "4   864975  2017-01-21 01:52:26.210827    control     old_page          1   \n",
       "\n",
       "   intercept  ab_page country  CA  UK  US  \n",
       "0          1        0      US   0   0   1  \n",
       "1          1        0      US   0   0   1  \n",
       "2          1        1      US   0   0   1  \n",
       "3          1        1      US   0   0   1  \n",
       "4          1        0      US   0   0   1  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.366113\n",
      "         Iterations 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>     <td>converted</td>    <th>  No. Observations:  </th>   <td>290584</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>   <td>290580</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>   <td>     3</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Tue, 12 Dec 2017</td> <th>  Pseudo R-squ.:     </th>  <td>2.323e-05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>19:45:56</td>     <th>  Log-Likelihood:    </th> <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th> <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th>   <td>0.1760</td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th> <td>   -2.0300</td> <td>    0.027</td> <td>  -76.249</td> <td> 0.000</td> <td>   -2.082</td> <td>   -1.978</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ab_page</th>   <td>   -0.0149</td> <td>    0.011</td> <td>   -1.307</td> <td> 0.191</td> <td>   -0.037</td> <td>    0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>UK</th>        <td>    0.0506</td> <td>    0.028</td> <td>    1.784</td> <td> 0.074</td> <td>   -0.005</td> <td>    0.106</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>US</th>        <td>    0.0408</td> <td>    0.027</td> <td>    1.516</td> <td> 0.130</td> <td>   -0.012</td> <td>    0.093</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:              converted   No. Observations:               290584\n",
       "Model:                          Logit   Df Residuals:                   290580\n",
       "Method:                           MLE   Df Model:                            3\n",
       "Date:                Tue, 12 Dec 2017   Pseudo R-squ.:               2.323e-05\n",
       "Time:                        19:45:56   Log-Likelihood:            -1.0639e+05\n",
       "converged:                       True   LL-Null:                   -1.0639e+05\n",
       "                                        LLR p-value:                    0.1760\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "intercept     -2.0300      0.027    -76.249      0.000      -2.082      -1.978\n",
       "ab_page       -0.0149      0.011     -1.307      0.191      -0.037       0.007\n",
       "UK             0.0506      0.028      1.784      0.074      -0.005       0.106\n",
       "US             0.0408      0.027      1.516      0.130      -0.012       0.093\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#instantiate, fit and run summary of new regression model with 'ab_page', 'UK', 'US', and Canada as the baseline\n",
    "logit_mod = sm.Logit(df2['converted'],df2[['intercept','ab_page','UK','US']])\n",
    "results = logit_mod.fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.95065885803307093, 0.96002111497165088)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculate magnitude at which baseline variable has effect over other categorical variables\n",
    "1/np.exp(.0506), 1/np.exp(.0408)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "intercept    0.131332\n",
       "ab_page      0.985168\n",
       "UK           1.051944\n",
       "US           1.041599\n",
       "dtype: float64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculate magnitude at which variables have effect over response variable\n",
    "np.exp(results.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the p-values and running this regression model under a two-sided hypothesis, it looks like we still don't have any statistical significance on our variables to say that they would have an influence on conversions. If we did have statistical significance, in order to interpret the results of the country variables here, we have to do so in terms of our baseline country variable, Canada. \n",
    "<br><br> If an individual lives in Canada, they are between .95 and .96 times more likely to convert than if they lived in the UK or US, holding all other variables constant.\n",
    "<br><br> If an individual is in the treatment group, they are .98 times more likely to convert, holding all other variables constant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "h. I'm now going to look at an interaction between page and country to see if there are significant effects on conversion.  We'll create the necessary additional columns, fit the new model, provide summary results, and conclusions based on the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "      <th>intercept</th>\n",
       "      <th>ab_page</th>\n",
       "      <th>country</th>\n",
       "      <th>CA</th>\n",
       "      <th>UK</th>\n",
       "      <th>US</th>\n",
       "      <th>US_ab</th>\n",
       "      <th>UK_ab</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>851104</td>\n",
       "      <td>2017-01-21 22:11:48.556739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>804228</td>\n",
       "      <td>2017-01-12 08:01:45.159739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>661590</td>\n",
       "      <td>2017-01-11 16:55:06.154213</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>853541</td>\n",
       "      <td>2017-01-08 18:28:03.143765</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>864975</td>\n",
       "      <td>2017-01-21 01:52:26.210827</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                   timestamp      group landing_page  converted  \\\n",
       "0   851104  2017-01-21 22:11:48.556739    control     old_page          0   \n",
       "1   804228  2017-01-12 08:01:45.159739    control     old_page          0   \n",
       "2   661590  2017-01-11 16:55:06.154213  treatment     new_page          0   \n",
       "3   853541  2017-01-08 18:28:03.143765  treatment     new_page          0   \n",
       "4   864975  2017-01-21 01:52:26.210827    control     old_page          1   \n",
       "\n",
       "   intercept  ab_page country  CA  UK  US  US_ab  UK_ab  \n",
       "0          1        0      US   0   0   1      0      0  \n",
       "1          1        0      US   0   0   1      0      0  \n",
       "2          1        1      US   0   0   1      1      0  \n",
       "3          1        1      US   0   0   1      1      0  \n",
       "4          1        0      US   0   0   1      0      0  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create new columns: 1 = both in that country and in treatment group, 0 = in that country and in control group\n",
    "df2['US_ab'] = np.multiply(df2['ab_page'],df2['US'])\n",
    "df2['UK_ab'] = np.multiply(df2['ab_page'],df2['UK'])\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.366109\n",
      "         Iterations 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>     <td>converted</td>    <th>  No. Observations:  </th>   <td>290584</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>   <td>290578</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>   <td>     5</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Tue, 12 Dec 2017</td> <th>  Pseudo R-squ.:     </th>  <td>3.482e-05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>19:47:22</td>     <th>  Log-Likelihood:    </th> <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th> <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th>   <td>0.1920</td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th> <td>   -2.0040</td> <td>    0.036</td> <td>  -55.008</td> <td> 0.000</td> <td>   -2.075</td> <td>   -1.933</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ab_page</th>   <td>   -0.0674</td> <td>    0.052</td> <td>   -1.297</td> <td> 0.195</td> <td>   -0.169</td> <td>    0.034</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>US</th>        <td>    0.0175</td> <td>    0.038</td> <td>    0.465</td> <td> 0.642</td> <td>   -0.056</td> <td>    0.091</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>UK</th>        <td>    0.0118</td> <td>    0.040</td> <td>    0.296</td> <td> 0.767</td> <td>   -0.066</td> <td>    0.090</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>US_ab</th>     <td>    0.0469</td> <td>    0.054</td> <td>    0.872</td> <td> 0.383</td> <td>   -0.059</td> <td>    0.152</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>UK_ab</th>     <td>    0.0783</td> <td>    0.057</td> <td>    1.378</td> <td> 0.168</td> <td>   -0.033</td> <td>    0.190</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:              converted   No. Observations:               290584\n",
       "Model:                          Logit   Df Residuals:                   290578\n",
       "Method:                           MLE   Df Model:                            5\n",
       "Date:                Tue, 12 Dec 2017   Pseudo R-squ.:               3.482e-05\n",
       "Time:                        19:47:22   Log-Likelihood:            -1.0639e+05\n",
       "converged:                       True   LL-Null:                   -1.0639e+05\n",
       "                                        LLR p-value:                    0.1920\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "intercept     -2.0040      0.036    -55.008      0.000      -2.075      -1.933\n",
       "ab_page       -0.0674      0.052     -1.297      0.195      -0.169       0.034\n",
       "US             0.0175      0.038      0.465      0.642      -0.056       0.091\n",
       "UK             0.0118      0.040      0.296      0.767      -0.066       0.090\n",
       "US_ab          0.0469      0.054      0.872      0.383      -0.059       0.152\n",
       "UK_ab          0.0783      0.057      1.378      0.168      -0.033       0.190\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_mod = sm.Logit(df2['converted'],df2[['intercept','ab_page','US','UK','US_ab','UK_ab']])\n",
    "results = logit_mod.fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.92468697883481332,\n",
       " 0.95418281110072634,\n",
       " 0.98826934696725455,\n",
       " 0.98265223566507331,\n",
       " intercept    0.134794\n",
       " ab_page      0.934776\n",
       " US           1.017682\n",
       " UK           1.011854\n",
       " US_ab        1.048001\n",
       " UK_ab        1.081428\n",
       " dtype: float64)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/np.exp(.0783), 1/np.exp(.0469), 1/np.exp(.0118), 1/np.exp(.0175), np.exp(results.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we have no variables that provide statistically significant evidence of having an influence on conversions. However, for the sake of explanation in the event that they did, let's interpret the influence of the variables.\n",
    "<br><br> If an individual lives in Canada _and_ is in the treatment group, they are .93 and .95 times more likely to convert than if they lived in the US or the UK and were in the treatment group, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's look at the duration of the A/B Test and given our results in these previous logistic regression models, make a recommendation to the company about how to proceed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.timedelta(22)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import date, datetime\n",
    "\n",
    "# duration of this experiment\n",
    "max_date = datetime.strptime(str(max(df['timestamp'])[0:10]), '%Y-%m-%d')\n",
    "min_date = datetime.strptime(str(min(df['timestamp'])[0:10]), '%Y-%m-%d')\n",
    "max_date - min_date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The duration of this A/B Test is 22 days long. I would recommend letting the test run for a few weeks longer in order to account for the change averse existing customers who may have been turned off by this new page feature and give them some time to get used to it. If we get similar results after a few weeks, I would recommend refraining from proceeding with implementation of this new web page."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
